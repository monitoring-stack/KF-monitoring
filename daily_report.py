import os
import json
import base64
from datetime import datetime
from html import escape
from collections import Counter

import feedparser
from bs4 import BeautifulSoup

from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib.units import mm

from helpers import date_de, classify


# ================== KONFIGURACE ==================

TIMEZONE = os.getenv("TIMEZONE", "Europe/Berlin")

RESEND_API_KEY = os.getenv("RESEND_API_KEY")
EMAIL_FROM = os.getenv("EMAIL_FROM")
EMAIL_TO = os.getenv("EMAIL_TO")
CC = os.getenv("CC")
BCC = os.getenv("BCC")

MAX_TOP = int(os.getenv("MAX_TOP", "10"))

FEEDS = [
    "https://news.google.com/rss/search?q=Kaufland+Deutschland&hl=de&gl=DE&ceid=DE:de",
    "https://news.google.com/rss/search?q=Kaufland+Filiale&hl=de&gl=DE&ceid=DE:de",
    "https://news.google.com/rss/search?q=Kaufland+Skandal+OR+R%C3%BCckruf+OR+Boykott&hl=de&gl=DE&ceid=DE:de",
]


# ================== POMOCN√â FUNKCE ==================


def classify_article(title: str, summary: str, link: str):
    """
    Navazuje na helpers.classify ‚Äì poƒç√≠t√°me s t√≠m, ≈æe m≈Ø≈æe vracet 3 nebo 4 hodnoty.
    My si vezmeme prvn√≠ 3 + zbytek ignorujeme.
    """
    host, src_type, base_score, *rest = classify(link, title)

    text = f"{title} {summary}".lower()

    # Kritick√© ‚Äì velmi √∫zk√©, aby se tam nedostala ka≈æd√° "po skand√°lu opƒõt otev≈ôeno"
    crit_keywords = [
        "r√ºckruf",
        "nicht essen",
        "nicht verzehren",
        "gesundheitsgefahr",
        "lebensgef√§hrlich",
        "vergiftung",
        "salmonell",
        "warnung",
        "gesundheitssch√§dlich",
    ]
    is_critical = any(kw in text for kw in crit_keywords)

    # Tematick√° kategorie ‚Äì jednoduch√°, ale srozumiteln√°
    category = "Sonstiges"
    if "r√ºckruf" in text or "qualit√§t" in text or "mangel" in text:
        category = "Qualit√§t & R√ºckruf"
    elif any(
        kw in text
        for kw in [
            "hygiene",
            "hygieneskandal",
            "filiale",
            "markt",
            "√∂ffnung",
            "er√∂ffnung",
            "umbau",
            "modernisiert",
        ]
    ):
        category = "Hygiene & Filialbetrieb"
    elif any(
        kw in text for kw in ["preise", "inflation", "rabatt", "angebot", "prospekt"]
    ):
        category = "Preis & Angebot"

    # Mezin√°rodn√≠ / vir√°ln√≠ ‚Äì velmi hrubƒõ podle dom√©ny
    is_international = not host.endswith(".de")

    return host, src_type, base_score, {
        "category": category,
        "critical": is_critical,
        "international": is_international,
    }


def fetch_news():
    """St√°hne v≈°echny ƒçl√°nky z RSS, odstran√≠ duplicity, nic zbyteƒçnƒõ nefiltruje."""
    seen = set()
    items = []

    for url in FEEDS:
        d = feedparser.parse(url)
        for e in d.entries:
            link = e.link
            if link in seen:
                continue
            seen.add(link)

            title = e.title
            desc_html = getattr(e, "summary", "")
            desc = BeautifulSoup(desc_html, "html.parser").get_text()
            if len(desc) > 260:
                desc = desc[:260] + "‚Ä¶"

            pub = getattr(e, "published", "")
            host, src_type, base_score, meta = classify_article(title, desc, link)

            items.append(
                {
                    "title": title,
                    "summary": desc,
                    "url": link,
                    "source": host,
                    "src_type": src_type,
                    "score": base_score,
                    "category": meta["category"],
                    "is_critical": meta["critical"],
                    "is_international": meta["international"],
                    "date": pub,
                }
            )

    # Se≈ôadit podle sk√≥re (nejd≈Øle≈æitƒõj≈°√≠ naho≈ôe)
    items.sort(key=lambda x: x["score"], reverse=True)
    return items


def bucket_by_category(items):
    buckets = {}
    for it in items:
        cat = it.get("category", "Sonstiges")
        buckets.setdefault(cat, []).append(it)

    # Preferovan√Ω po≈ôadn√≠k kategori√≠
    order = ["Qualit√§t & R√ºckruf", "Hygiene & Filialbetrieb", "Preis & Angebot", "Sonstiges"]
    sorted_buckets = []

    for cat in order:
        if cat in buckets:
            sorted_buckets.append((cat, buckets[cat]))
    # p≈ô√≠padn√© dal≈°√≠ kategorie za t√≠m
    for cat, lst in buckets.items():
        if cat not in order:
            sorted_buckets.append((cat, lst))

    return sorted_buckets


# ================== PDF ==================


def build_pdf(filename, items):
    styles = getSampleStyleSheet()
    doc = SimpleDocTemplate(
        filename,
        pagesize=A4,
        leftMargin=18 * mm,
        rightMargin=18 * mm,
        topMargin=16 * mm,
        bottomMargin=16 * mm,
    )

    story = []

    title = f"DE Monitoring ‚Äì privat | {date_de(TIMEZONE)}"
    story.append(Paragraph(title, styles["Title"]))
    story.append(Spacer(1, 8))

    total = len(items)
    crit = sum(1 for i in items if i["is_critical"])
    intl = sum(1 for i in items if i["is_international"])

    intro = (
        f"Insgesamt {total} Artikel im Auswertungszeitraum. "
        f"{crit} davon als kritisch eingestuft, "
        f"{intl} virale / internationale Erw√§hnungen."
    )
    story.append(Paragraph(intro, styles["Normal"]))
    story.append(Spacer(1, 12))

    # Skupiny dle kategori√≠
    for cat, lst in bucket_by_category(items):
        story.append(Paragraph(cat, styles["Heading1"]))
        story.append(Spacer(1, 6))

        for it in lst:
            # Titulek
            line_title = f"{escape(it['title'])}"
            story.append(Paragraph(line_title, styles["Heading3"]))

            # Meta + ≈°t√≠tky
            badges = []
            if it["is_critical"]:
                badges.append("‚ñ† Kritisch")
            if it["is_international"]:
                badges.append("‚óè Virale / internationale Erw√§hnung")

            meta_parts = [escape(it["source"])]
            if it.get("date"):
                meta_parts.append(escape(it["date"]))
            if badges:
                meta_parts.append(" / ".join(badges))

            meta_line = " ¬∑ ".join(meta_parts)
            story.append(Paragraph(meta_line, styles["Normal"]))

            # Kr√°tk√Ω klikac√≠ odkaz ‚Äì jen hlavn√≠ URL, ne cel√© RSS
            link_html = f'<a href="{it["url"]}">Link</a>'
            story.append(Paragraph(link_html, styles["Normal"]))

            story.append(Spacer(1, 6))

    doc.build(story)


# ================== EMAIL (HTML) ==================


def build_email_html(items):
    date_str = date_de(TIMEZONE)
    total = len(items)
    critical_count = sum(1 for x in items if x["is_critical"])
    international_count = sum(1 for x in items if x["is_international"])

    theme_counts = Counter(x["category"] for x in items)
    themes_str = ", ".join(f"{k} ({v})" for k, v in theme_counts.items())

    # --- Executive Summary ---
    executive_summary_html = f"""
    Heute wurden insgesamt <b>{total}</b> relevante Erw√§hnungen zu Kaufland erfasst.<br>
    Davon sind <b>{critical_count}</b> als potentiell kritisch (R√ºckruf, Qualit√§t, Gesundheitsrisiken) eingestuft.<br>
    Zus√§tzlich gibt es <b>{international_count}</b> virale / internationale Erw√§hnungen.<br><br>
    Thematisch dominieren heute: <b>{escape(themes_str)}</b>.
    """.strip()

    # --- Top Headlines ---
    top_n = min(MAX_TOP, len(items))
    top_items = sorted(items, key=lambda x: x["score"], reverse=True)[:top_n]

    top_lines = []
    for idx, it in enumerate(top_items, start=1):
        badges = []
        if it["is_critical"]:
            badges.append("‚ö† Kritisch")
        if it["is_international"]:
            badges.append("üåç Virale Erw√§hnung")
        badge_str = " ¬∑ ".join(badges)

        meta_parts = [escape(it["source"])]
        if it.get("date"):
            meta_parts.append(escape(it["date"]))
        if badge_str:
            meta_parts.append(badge_str)
        meta = " ¬∑ ".join(meta_parts)

        line = (
            f'<p>{idx}. '
            f'<a href="{it["url"]}">{escape(it["title"])}</a><br>'
            f'<span style="font-size:12px;color:#555;">{meta}</span></p>'
        )
        top_lines.append(line)

    top_block_html = "\n".join(top_lines)

    # --- International / Viral Section ---
    intl_items = [x for x in items if x["is_international"]]
    intl_lines = []
    for it in intl_items[:5]:
        meta_parts = [escape(it["source"])]
        if it.get("date"):
            meta_parts.append(escape(it["date"]))
        if it["is_critical"]:
            meta_parts.append("‚ö† Kritisch")
        meta = " ¬∑ ".join(meta_parts)

        intl_lines.append(
            f'<li><a href="{it["url"]}">{escape(it["title"])}</a>'
            f'<br><span style="font-size:12px;color:#555;">{meta}</span></li>'
        )

    if intl_lines:
        international_block_html = (
            "<h3>Internationale / virale Erw√§hnungen</h3><ul>"
            + "\n".join(intl_lines)
            + "</ul>"
        )
    else:
        international_block_html = ""

    # --- Naƒçteme HTML ≈°ablonu a nahrad√≠me placeholdery ---
    with open("email_template.html", "r", encoding="utf-8") as f:
        template_str = f.read()

    replacements = {
        "{date_str}": date_str,
        "{tz}": TIMEZONE,
        "{total_count}": str(total),
        "{critical_count}": str(critical_count),
        "{international_count}": str(international_count),
        "{themes_str}": themes_str,
        "{executive_summary_html}": executive_summary_html,
        "{top_headlines_html}": top_block_html,
        "{international_block_html}": international_block_html,
        "{top_count}": str(top_n),
    }

    html = template_str
    for key, val in replacements.items():
        html = html.replace(key, val)

    return html


# ================== RESEND ==================


def send_via_resend(subject, html, pdf_name):
    if not RESEND_API_KEY:
        raise RuntimeError("RESEND_API_KEY env variable is missing.")
    if not EMAIL_FROM:
        raise RuntimeError("EMAIL_FROM env variable is missing.")
    if not EMAIL_TO:
        raise RuntimeError("EMAIL_TO env variable is missing.")

    with open(pdf_name, "rb") as f:
        pdf_bytes = f.read()
    pdf_b64 = base64.b64encode(pdf_bytes).decode("ascii")

    payload = {
        "from": EMAIL_FROM,
        "to": [EMAIL_TO],
        "subject": subject,
        "html": html,
        "attachments": [
            {
                "filename": pdf_name,
                "content": pdf_b64,
            }
        ],
    }

    if CC:
        payload["cc"] = [x.strip() for x in CC.split(",") if x.strip()]
    if BCC:
        payload["bcc"] = [x.strip() for x in BCC.split(",") if x.strip()]

    data_bytes = json.dumps(payload).encode("utf-8")

    import urllib.request
    import urllib.error

    req = urllib.request.Request(
        "https://api.resend.com/emails",
        data=data_bytes,
        headers={
            "Authorization": f"Bearer {RESEND_API_KEY}",
            "Content-Type": "application/json",
        },
        method="POST",
    )

    try:
        with urllib.request.urlopen(req) as resp:
            body = resp.read().decode("utf-8")
            print("Resend response:", resp.status, body)
    except urllib.error.HTTPError as e:
        print("Resend HTTP error:", e.code, e.read().decode("utf-8"))
        raise
    except urllib.error.URLError as e:
        print("Resend connection error:", e.reason)
        raise


# ================== MAIN ==================


def main():
    items = fetch_news()
    if not items:
        print("No items found for today ‚Äì email not sent.")
        return

    pdf_name = f"DE_monitoring_privat_{datetime.now().strftime('%Y-%m-%d')}.pdf"
    build_pdf(pdf_name, items)

    html = build_email_html(items)
    subject = f"Kaufland Media & Review Briefing ‚Äì Deutschland | {date_de(TIMEZONE)}"

    print("Sending email to", EMAIL_TO)
    send_via_resend(subject, html, pdf_name)


if __name__ == "__main__":
    main()
